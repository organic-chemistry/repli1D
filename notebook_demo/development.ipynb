{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "df = pd.read_csv('../development/K562_mean_attributions.csv')\n",
    "fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(df))\n",
    "# fig.add_trace(go.Scatter(x=list(df.index[df['chrom'] == 'chr1']*2000),\n",
    "marks = ['H2A.Z', 'H3K27ac', 'H3K79me2', 'H3K27me3',\n",
    "                                 'H3K9ac', 'H3K4me2', 'H3K4me3', 'H3K9me3',\n",
    "                                 'H3K4me1', 'H3K36me3', 'H4K20me1']\n",
    "attributions = ['Attribution_H2A.Z', 'Attributions_H3K27ac', 'Attributions_H3K79me2', 'Attributions_H3K27me3',\n",
    "                                 'Attributions_H3K9ac', 'Attributions_H3K4me2', 'Attributions_H3K4me3', 'Attributions_H3K9me3',\n",
    "                                 'Attributions_H3K4me1', 'Attributions_H3K36me3', 'Attributions_H4K20me1']\n",
    "fig = px.line(df, x=df.index*2000, y=df.columns[1:], \n",
    "              color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "fig.update_layout(\n",
    "    title=\"Attributions from integrated gradient\",\n",
    "    xaxis_title=\"Genomic position (bp)\",\n",
    "    yaxis_title=\"attributions and podls\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_html(\"../development/attributions_mean_baseline_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../development/K562_attributions.csv')\n",
    "X = df[df.columns[1:]].to_numpy()\n",
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\n",
    "        \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "class MLP(nn.Module):\n",
    "    # def __init__(self):\n",
    "    def __init__(self, units=100):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(11, units)\n",
    "        self.lin2 = nn.Linear(units, 1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = F.relu(self.lin1(xb))\n",
    "        xb = F.relu(self.lin2(xb))\n",
    "        return xb\n",
    "model = MLP()\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load('../development/model_weights.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "X_test = torch.Tensor([1, 0.75, 0.8, 0.9, 1, 0.75, 1, 1.5, 0.75, 1, 1])\n",
    "predicted = model(X_test).detach().cpu().numpy()\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlations for attributions\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "df = pd.read_csv('../development/K562_zero_output_attributions.csv')\n",
    "# for i in df[df.columns[1:14]]:\n",
    "#     # df.loc[df[i] == 0, i] = np.min(df[i][(df[i] != 0)])\n",
    "#     df[i] = df[i] + np.min(df[i][(df[i] != 0)])\n",
    "#     df[i] = np.log10(df[i])\n",
    "corrMatrix = df[df.columns[1:14]].corr(method='spearman')\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax = sns.clustermap(corrMatrix, annot=True, row_cluster=True,\n",
    "                        col_cluster=True, metric='correlation',\n",
    "                        cmap=sns.diverging_palette(220, 20, n=50))  # cbar_pos=(0, .2, .03, .4)\n",
    "plt.title(\"Spearman correlation coefficients for attributions of K562 epigenetic markers\", x=10, y=1)\n",
    "plt.savefig('../development/correlation_of_attributions.png',\n",
    "            dpi=300, bbox_inches='tight', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum of attributions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('../development/K562_mean_attributions.csv')\n",
    "df = df[df.columns[1:12]]\n",
    "df[df.columns] = np.sum(df)\n",
    "print(df.sort_values(by=1, axis=1))\n",
    "df = df.sort_values(by=1, axis=1)\n",
    "plt.bar(df.columns, df.iloc[1, :])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Sum of attributions')\n",
    "plt.savefig('../development/sum_of_attributions.png',\n",
    "            dpi=300, bbox_inches='tight', transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv('../development/K562_mean_attributions.csv')\n",
    "plt.rcParams['font.size'] = '24'\n",
    "df = df[df.columns[1:12]]\n",
    "plt.figure(figsize=(40, 25))\n",
    "sns.violinplot(data=df)\n",
    "# ax = plt.violinplot(df, xticks=df.columns)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of attributions')\n",
    "plt.savefig('../development/distribution_of_attributions.png',\n",
    "            dpi=300, bbox_inches='tight', transparent=False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('repli-pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ebc8463b9979005ec4107cdc7e2edf6b7a0486ef72204c6f17c8529af57a442"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
